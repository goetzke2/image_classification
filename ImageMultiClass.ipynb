{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kerry\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kerry\\OneDrive\\HAP 774\\all-mg-codes.txt\", delimiter='xxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image'] = df.apply(lambda r: r[0].split('\\t')[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classes'] = df.apply(lambda r: r[0].split('\\t')[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df['image'],df['classes'].str.split(' ', expand=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values[1] = \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im0002</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im0003</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im0004</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im0005</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im0006</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>im0007</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>im0008</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>im0009</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>im0010</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im0011</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>im0012</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>im0013</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>im0014</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>im0015</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>im0016</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>im0017</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>im0018</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>im0019</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>im0020</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>im0021</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>im0022</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>im0023</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>im0024</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>im0025</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>im0026</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>im0027</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>im0028</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>im0029</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>im0030</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>im0031</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>im0373</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>im0374</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>im0375</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>im0376</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>im0377</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>im0378</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>im0379</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>im0380</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>im0381</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>im0382</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>im0383</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>im0384</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>im0385</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>im0386</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>im0387</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>im0388</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>im0389</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>im0390</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>im0391</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>im0392</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>im0393</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>im0394</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>im0395</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>im0396</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>im0397</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>im0398</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>im0399</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>im0400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>im0401</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>im0402</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  class     1     2     3\n",
       "0    im0002     13     9  None  None\n",
       "1    im0003     14  None  None  None\n",
       "2    im0004     14     3  None  None\n",
       "3    im0005      3     5  None  None\n",
       "4    im0006     14  None  None  None\n",
       "5    im0007     13    14     9    10\n",
       "6    im0008     13    14     9  None\n",
       "7    im0009      7  None  None  None\n",
       "8    im0010     14  None  None  None\n",
       "9    im0011     13    14  None  None\n",
       "10   im0012     14  None  None  None\n",
       "11   im0013      7  None  None  None\n",
       "12   im0014     14  None  None  None\n",
       "13   im0015     14  None  None  None\n",
       "14   im0016      7  None  None  None\n",
       "15   im0017     13  None  None  None\n",
       "16   im0018      5  None  None  None\n",
       "17   im0019      5  None  None  None\n",
       "18   im0020      3     5  None  None\n",
       "19   im0021      8  None  None  None\n",
       "20   im0022      9  None  None  None\n",
       "21   im0023     14  None  None  None\n",
       "22   im0024     14  None  None  None\n",
       "23   im0025      5     9  None  None\n",
       "24   im0026      5  None  None  None\n",
       "25   im0027      5  None  None  None\n",
       "26   im0028      6     9  None  None\n",
       "27   im0029     14  None  None  None\n",
       "28   im0030      0  None  None  None\n",
       "29   im0031      7  None  None  None\n",
       "..      ...    ...   ...   ...   ...\n",
       "366  im0373     13    14  None  None\n",
       "367  im0374     14  None  None  None\n",
       "368  im0375     13    14  None  None\n",
       "369  im0376     13    14  None  None\n",
       "370  im0377     13    14  None  None\n",
       "371  im0378     13    10    14  None\n",
       "372  im0379     13    14  None  None\n",
       "373  im0380     13    14  None  None\n",
       "374  im0381     13     9    14  None\n",
       "375  im0382     13    14  None  None\n",
       "376  im0383     13    14  None  None\n",
       "377  im0384     13    14  None  None\n",
       "378  im0385     13    14  None  None\n",
       "379  im0386     14  None  None  None\n",
       "380  im0387     14  None  None  None\n",
       "381  im0388     14  None  None  None\n",
       "382  im0389     14  None  None  None\n",
       "383  im0390     14  None  None  None\n",
       "384  im0391     14  None  None  None\n",
       "385  im0392     14  None  None  None\n",
       "386  im0393     14  None  None  None\n",
       "387  im0394     14  None  None  None\n",
       "388  im0395     14  None  None  None\n",
       "389  im0396     10     9  None  None\n",
       "390  im0397     10  None  None  None\n",
       "391  im0398     10     9  None  None\n",
       "392  im0399      2     1     9  None\n",
       "393  im0400      2     1     9  None\n",
       "394  im0401     14  None  None  None\n",
       "395  im0402     14  None  None  None\n",
       "\n",
       "[396 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eea4165f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x = 'class', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001EEA63EEB00>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    100\n",
       "7      66\n",
       "13     61\n",
       "0      39\n",
       "8      23\n",
       "5      23\n",
       "10     16\n",
       "11     14\n",
       "6      12\n",
       "4      11\n",
       "12      8\n",
       "2       7\n",
       "3       6\n",
       "9       5\n",
       "1       5\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im0002</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im0003</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im0004</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im0005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im0006</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image  class\n",
       "0  im0002     13\n",
       "1  im0003     14\n",
       "2  im0004     14\n",
       "3  im0005      3\n",
       "4  im0006     14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['image', 'class']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eDL(Dataset):\n",
    "    def __init__(self, labels, transform=None, target_transform=None):\n",
    "        self.img_labels = labels\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "\n",
    "        img_path = \"C:/Users/kerry/OneDrive/HAP 774/all-images/\" + self.img_labels.loc[idx,'image'] + '.ppm'\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "        label = self.img_labels.loc[idx, 'class']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #if self.target_transform:\n",
    "        #    label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    object\n",
       "class     int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    object\n",
       "class     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['class'] = df['class'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(\n",
    "     #   mean=[0.485, 0.456, 0.406],\n",
    "      #  std=[0.229, 0.224, 0.225])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1, random_state=1000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = df[:int(len(df)*0.8)].reset_index(drop=True)\n",
    "ts_df = df[int(len(df)*0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>im0050</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image  class\n",
       "6  im0050      7"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df[ts_df['image'] == 'im0050']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=eDL(tr_df[['image','class']], preprocess)\n",
    "ts=eDL(ts_df[['image','class']], preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tr, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(ts, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 3, 224, 224])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#X is image\n",
    "#y is label\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]:  torch.Size([64, 3, 224, 224])\n",
      "Shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#X is image\n",
    "#y is label\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1\n",
    "#color images have 3 channels - RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 12, 4, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(12, 24, 4, 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(in_features=69984, out_features=50),\n",
    "            #nn.Linear(in_features = 12*111*111, out_features = 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 15)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print(\"original\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        #print(\"after conv1\", x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        #print(\"after conv2\", x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        #print(\"after flatten\",x.shape)\n",
    "\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        #print('final ', logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn = nn.MultiMarginLoss()\n",
    "#loss_fn = nn.MSELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to('cpu'), y.to('cpu')\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to('cpu'), y.to('cpu')\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.int).sum().item()\n",
    "            #correct += (pred.argmax(1) == y).type(torch.long).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.686572  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 33.8%, Avg loss: 2.578592 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.601370  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.495837 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.510431  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.439005 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.498717  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.447237 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.329591  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.426916 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.397904  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.356873 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.296117  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.270365 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.265572  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.267853 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.221712  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.204846 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.324513  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.462940 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.369294  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.218062 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.331299  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.325815 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.309146  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.295385 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.383879  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.278605 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.253644  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.231437 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.448603  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.336839 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.310114  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.312314 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.207499  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.234367 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.190094  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.264151 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.231737  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.175573 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.326345  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.204461 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.334980  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.096448 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.206465  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.310353 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.337918  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.277941 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.196439  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.474647 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.301524  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.191363 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.240463  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.264673 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.304432  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.137442 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.189371  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.186291 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.414700  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.194772 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.232150  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.326767 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.177681  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.145796 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.339547  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.243875 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.332587  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.093187 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.350859  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.180056 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.349436  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.199272 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.144953  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.229189 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.480489  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.192375 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.310949  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.219038 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.243134  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.327511 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.230943  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.179193 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.415355  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.230628 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.217840  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.303500 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.464505  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.244267 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.158862  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.285211 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.262281  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.292558 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.413489  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.232502 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.333332  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.246635 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.254568  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.215497 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.220090  [    0/  316]\n",
      "Test Error: \n",
      " Accuracy: 26.2%, Avg loss: 2.304239 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in resnet.parameters():\n",
    "    w.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(2048, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kerry\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.729172  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 1.2%, Avg loss: 2.774575 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.713650  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 5.0%, Avg loss: 2.778801 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.739743  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 7.5%, Avg loss: 2.730720 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.722939  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 7.5%, Avg loss: 2.762295 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.708504  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 10.0%, Avg loss: 2.730024 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.752033  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 7.5%, Avg loss: 2.766034 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.686816  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 7.5%, Avg loss: 2.753326 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.728656  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.759012 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.749501  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 5.0%, Avg loss: 2.689565 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.731131  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 3.8%, Avg loss: 2.716943 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.724736  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 5.0%, Avg loss: 2.750535 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.680972  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.769822 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.760528  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.681943 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.711992  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.757383 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.734653  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.716486 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 2.692423  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.721985 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 2.719883  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.724182 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 2.735251  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.712130 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 2.683385  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.736382 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 2.714230  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.727273 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 2.751831  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.728094 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 2.727439  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.709513 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 2.737353  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.722113 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 2.710181  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.748445 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 2.714413  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.702382 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 2.684041  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.756517 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 2.684585  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.714615 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 2.755019  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.741464 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 2.675387  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.742521 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 2.748276  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.737988 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 2.692174  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.758067 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 2.750033  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.737802 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 2.742802  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.689329 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 2.793623  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.747889 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 2.705076  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.741816 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 2.676675  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.723208 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 2.742815  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.708797 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 2.716244  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.721932 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 2.698821  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.732758 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 2.742470  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.756385 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 2.761882  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.748299 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 2.758697  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.734326 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 2.777341  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.711576 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 2.712491  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.705173 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 2.743424  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.717671 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 2.727833  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.750150 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 2.716921  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.712503 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 2.673385  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.712747 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 2.728299  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.751051 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 2.725488  [    0/  316]\n",
      "after train\n",
      "Test Error: \n",
      " Accuracy: 6.2%, Avg loss: 2.718256 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, resnet, loss_fn, optimizer)\n",
    "    print('after train')\n",
    "    test(test_dataloader, resnet, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
